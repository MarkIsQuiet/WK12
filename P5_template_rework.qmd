---
title: "Client Report - The War with Star Wars"
subtitle: "Course DS 250"
author: "Mark Rowley"
format:
  html:
    self-contained: true
    page-layout: full
    title-block-banner: true
    toc: true
    toc-depth: 3
    toc-location: body
    number-sections: false
    html-math-method: katex
    code-fold: true
    code-summary: "Show the code"
    code-overflow: wrap
    code-copy: hover
    code-tools:
        source: false
        toggle: true
        caption: See code
execute: 
  warning: false
    
---

```{python}
import pandas as pd 
import numpy as np
from lets_plot import *
# add the additional libraries you need to import for ML here

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score

LetsPlot.setup_html(isolated_frame=True)
pd.set_option("display.max_rows", None)
pd.set_option("display.max_columns", None)
```


```{python}
# Learn morea about Code Cells: https://quarto.org/docs/reference/cells/cells-jupyter.html

# Include and execute your code here

# import your data here using pandas and the URL
df = pd.read_csv("StarWars.csv", encoding="cp1252")
df.columns = df.columns.str.encode('ascii', 'ignore').str.decode('ascii')
```

```{python}
#df.columns
```

```{python}
#df.head()
```

```{python}
#print(df.iloc[0:6])
```


## Elevator pitch
_A SHORT (2-3 SENTENCES) PARAGRAPH THAT `DESCRIBES KEY INSIGHTS` TAKEN FROM METRICS IN THE PROJECT RESULTS THINK TOP OR MOST IMPORTANT RESULTS._ (Note: this is not a summary of the project, but a summary of the results.)

_We were able to organize the data provided and create a working model. However, with how scattered the responses have been, and the wide breadth of respondents, there is a lot of conflicting and useless data. A lot of it having very little to do with determining who of the respondents makes more or less than the target you provided. In the end, the model has an accuracy of 65%. Best case scenario is that you can guess 13 out of 20 respondents correctly. We can try other variations of cleaning data and organization, different models and such. But in the given time, this is what we can provide._

## QUESTION|TASK 1

__Shorten the column names and clean them up for easier use with pandas.__ Provide a table or list that exemplifies how you fixed the names. 

_I shortened the names of all columns into something easy to type, understand, and work with while working with data visualization and model training/testing. I then dropped the now-useless row 0._

```{python}
# Include and execute your code here
df_name = df.dropna(how = "all").copy()

rename_map = {
    'RespondentID': 'response_id',
    'Have you seen any of the 6 films in the Star Wars franchise?': 'seen_any_film',
    'Do you consider yourself to be a fan of the Star Wars film franchise?': 'star_wars_fan',
    'Which of the following Star Wars films have you seen? Please select all that apply.': 'seen_episode_1',
    'Unnamed: 4': 'seen_episode_2', 
    'Unnamed: 5': 'seen_episode_3', 
    'Unnamed: 6': 'seen_episode_4', 
    'Unnamed: 7': 'seen_episode_5', 
    'Unnamed: 8': 'seen_episode_6',
    'Please rank the Star Wars films in order of preference with 1 being your favorite film in the franchise and 6 being your least favorite film.': 'episode_1_rank',
    'Unnamed: 10': 'episode_2_rank', 
    'Unnamed: 11': 'episode_3_rank', 
    'Unnamed: 12': 'episode_4_rank', 
    'Unnamed: 13': 'episode_5_rank',
    'Unnamed: 14': 'episode_6_rank',
    'Please state whether you view the following characters favorably, unfavorably, or are unfamiliar with him/her.': 'favored_han_solo',
    'Unnamed: 16': 'favored_luke_skywalker', 
    'Unnamed: 17': 'favored_leia_organa', 
    'Unnamed: 18': 'favored_anakin_skywalker', 
    'Unnamed: 19': 'favored_obi_wan',
    'Unnamed: 20': 'favored_palpatine', 
    'Unnamed: 21': 'favored_darth_vader', 
    'Unnamed: 22': 'favored_lando', 
    'Unnamed: 23': 'favored_boba_fett',
    'Unnamed: 24': 'favored_c3po', 
    'Unnamed: 25': 'favored_r2d2', 
    'Unnamed: 26': 'favored_jar_jar', 
    'Unnamed: 27': 'favored_padme_amidala',
    'Unnamed: 28': 'favored_yoda', 
    'Which character shot first?': 'unknown_question',
    'Are you familiar with the Expanded Universe?': 'know_of_expanded_universe',
    'Do you consider yourself to be a fan of the Expanded Universe?': 'expanded_universe_fan',
    'Do you consider yourself to be a fan of the Star Trek franchise?': 'star_trek_fan',
    'Gender': 'gender', 'Age': 'age', 'Household Income': 'income', 'Education': 'education',
    'Location (Census Region)': 'region'
}

df_name = df_name.rename(columns=rename_map)
df_name = df_name.drop(0)

print(df_name.columns)
```


## QUESTION|TASK 2

__Clean and format the data so that it can be used in a machine learning model.__ As you format the data, you should complete each item listed below. In your final report provide example(s) of the reformatted data with a short description of the changes made.  
    a. Filter the dataset to respondents that have seen at least one film  
    b. Create a new column that converts the age ranges to a single number. Drop the age range categorical column  
    c. Create a new column that converts the education groupings to a single number. Drop the school categorical column  
    d. Create a new column that converts the income ranges to a single number. Drop the income range categorical column  
    e. Create your target (also known as “y” or “label”) column based on the new income range column  
    f. One-hot encode all remaining categorical columns   

_We first only included those that have seen any of the films. From there, we simplified the age, education, and income down to integer groups for easy training and understanding.To wrap things up, we created the target column we will be using to train later, and encoded the remaining features to make them easier to understand for the model._

```{python}
# Include and execute your code here
  # Part A
df_A = df_name[df_name['seen_any_film'] == "Yes"]

#df_A.head()
```

```{python}
# Include and execute your code here
  # Part B
df_B = df_A.copy()
age_group = {
  '18-29': '1',
  '30-44': '2',
  '45-60': '3',
  '> 60': '4'
}

df_B['age_group'] = df_B['age'].map(age_group)
df_B['age_group'] = df_B['age_group'].fillna(0)
df_B['age_group'] = df_B['age_group'].astype(int)
df_B.drop("age", axis=1, inplace=True)

#df_B.head()
```

```{python}
# Include and execute your code here
  # Part C
df_C = df_B.copy()
education_level = {
  'Less than high school degree': '1',
  'High school degree': '2',
  'Some college or Associate degree': '3',
  'Bachelor degree': '4'
}

df_C['education_level'] = df_C['education'].map(education_level)
df_C['education_level'] = df_C['education_level'].fillna(0)
df_C['education_level'] = df_C['education_level'].astype(int)
df_C.drop("education", axis=1, inplace=True)

#df_C.head()
```

```{python}
# Include and execute your code here
  # Part D
df_D = df_C.copy()
income_level = {
  '$0 - $24,999': '1',
  '$25,000 - $49,999': '2',
  '$50,000 - $99,999': '3',
  '$100,000 - $149,999': '4',
  '$150,000+': '5'
}

df_D['income_level'] = df_D['income'].map(income_level)
df_D['income_level'] = df_D['income_level'].fillna(0)
df_D['income_level'] = df_D['income_level'].astype(int)
df_D.drop("income", axis=1, inplace=True)

#df_D.head()
```

```{python}
# Include and execute your code here
  # Part E
df_E = df_D.copy()

df_E['target'] = df_E['income_level'] >= 3

#df_E.head()
#df_E.columns
```

```{python}
# Include and execute your code here
  # Part F.2
df_encoded = pd.get_dummies(df_E, columns=['gender', 'region', 'seen_any_film', 'star_wars_fan', 'seen_episode_1',
       'seen_episode_2', 'seen_episode_3', 'seen_episode_4', 'seen_episode_5',
       'seen_episode_6', 'episode_1_rank', 'episode_2_rank', 'episode_3_rank',
       'episode_4_rank', 'episode_5_rank', 'episode_6_rank',
       'favored_han_solo', 'favored_luke_skywalker', 'favored_leia_organa',
       'favored_anakin_skywalker', 'favored_obi_wan', 'favored_palpatine',
       'favored_darth_vader', 'favored_lando', 'favored_boba_fett',
       'favored_c3po', 'favored_r2d2', 'favored_jar_jar',
       'favored_padme_amidala', 'favored_yoda', 'unknown_question',
       'know_of_expanded_universe', 'expanded_universe_fan', 'star_trek_fan'])

df_encoded.head()

```

## QUESTION|TASK 3

__Validate that the data provided on GitHub lines up with the article by recreating 2 of the visuals from the article.__  

_This first chart is a rough copy from the article provided on what the best move was. It has the same total, as well as the same percentages depicted._

```{python}
# Include and execute your code here
len(df_encoded.dropna())
len(df_A)
print(df_encoded.columns.tolist())
```

```{python}
# Include and execute your code here
cols_to_check = ['seen_episode_1_Star Wars: Episode I  The Phantom Menace', 'seen_episode_2_Star Wars: Episode II  Attack of the Clones', 'seen_episode_3_Star Wars: Episode III  Revenge of the Sith', 'seen_episode_4_Star Wars: Episode IV  A New Hope', 'seen_episode_5_Star Wars: Episode V The Empire Strikes Back', 'seen_episode_6_Star Wars: Episode VI Return of the Jedi']

# Count rows where all 6 are True
count_all_true = (df_encoded[cols_to_check].all(axis=1)).sum()

print("Rows where all 6 columns are True:", count_all_true)

df_bingePrep = df_encoded[df_encoded[cols_to_check].all(axis=1)]


```

```{python}
# Include and execute your code here
  # Best SW Movie by All 471
film_favorite = [
    "episode_1_rank_1",
    "episode_2_rank_1",
    "episode_3_rank_1",
    "episode_4_rank_1",
    "episode_5_rank_1",
    "episode_6_rank_1"
]

film_labels = {
    "episode_1_rank_1": "The Phantom Menace",
    "episode_2_rank_1": "Attack of the Clones",
    "episode_3_rank_1": "Revenge of the Sith",
    "episode_4_rank_1": "A New Hope",
    "episode_5_rank_1": "The Empire Strikes Back",
    "episode_6_rank_1": "Return of the Jedi"
}

df_binge_one = df_bingePrep[film_favorite]
#df_binge_one.head()

# Count how many respondents favored each film
fav_counts = df_binge_one[film_favorite].sum()

df_plot1 = fav_counts.reset_index()
df_plot1.columns = ['Film', 'Total']

df_plot1["Film"] = df_plot1["Film"].replace(film_labels)

df_plot1["Percent"] = (df_plot1["Total"] / df_plot1["Total"].sum()) * 100

(
  ggplot(
    data = df_plot1,
    mapping = aes(x = 'Film', y = 'Total')
  )
  + geom_bar(stat = 'identity', width=0.5)
  + coord_flip()
  + geom_text(
      aes(
          label=df_plot1["Percent"].round(0).astype(str) + "%"
      ),
      ha="left",
      nudge_y = 12, 
      size = 7
  )
  + labs(
    x = "Film",
    y = "Total",
    title = "What's the 'best' Star Wars Movie?"
  )
)
```

## QUESTION|TASK 4

__Build a machine learning model that predicts whether a person makes more than $50k. Describe your model and report the accuracy.__ 

_Well, the model pulls the target of them being in the income level or higher, and makes that the y or target of the model. It also drops both the income and the target, since they ultimatly are the same thing and provide a 100% accuracy otherwise. The RandomForest trains on scaled data, with 10% of the data given being used to test the model, and the other 90% to train. The final accuracy provided is 65%, which means that we predict correctly for 13 out of 20 predictions made with this model._

```{python}
#df_encoded.columns
```

```{python}
# Include and execute your code here
df_mod = df_encoded.copy()
target = df_mod['target']
features = df_mod.drop(['target', 'income_level'], axis = 1)
#print(features)
#print(target)
```

```{python}
  # Training Split
 # Training Split & Scaling
X_train, X_test, y_train, y_test = train_test_split(
  features, target, test_size=0.1, random_state=42, stratify = target
)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
```

```{python}

  # Train Regression Model
rf = RandomForestClassifier(n_estimators=400, max_depth=9, random_state=42, n_jobs=-1)
rf.fit(X_train_scaled, y_train)

  # Evaluate
y_pred = rf.predict(X_test_scaled)
acc = accuracy_score(y_test, y_pred)

  # Display Statistics
print("\nLogistic regression results:")
print("Test accuracy: {:.2f}".format(acc))
```

---

## STRETCH QUESTION|TASK 1

__Build a machine learning model that predicts whether a person makes more than $50k. With accuracy of at least 65%. Describe your model and report the accuracy.__

_type your results and analysis here_

```{python}
# Include and execute your code here


```


## STRETCH QUESTION|TASK 2

__Validate the data provided on GitHub lines up with the article by recreating a 3rd visual from the article.__

_type your results and analysis here_

```{python}
# Include and execute your code here


```


## STRETCH QUESTION|TASK 3

__Create a new column that converts the location groupings to a single number. Drop the location categorical column.__  

_type your results and analysis here_

```{python}
# Include and execute your code here


```

---
